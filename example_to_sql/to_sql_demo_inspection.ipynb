{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance showcase of added \"to_sql\" functionality in mlinspect\n",
    "\n",
    "Here the performance of the proposed inspection using sql will be compared to the original one in pandas. Part of\n",
    "the \"healthcare\" and \"compas\" pipeline will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages:\n",
    "See: requirements/requirements.txt and requirements/requirements.dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some parameters you might want to set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from mlinspect.utils import get_project_root\n",
    "from mlinspect import PipelineInspector, OperatorType\n",
    "from mlinspect.inspections import HistogramForColumns, RowLineage, MaterializeFirstOutputRows\n",
    "from mlinspect.checks import NoBiasIntroducedFor, NoIllegalFeatures\n",
    "from demo.feature_overview.no_missing_embeddings import NoMissingEmbeddings\n",
    "from example_pipelines.healthcare import custom_monkeypatching\n",
    "from mlinspect.to_sql.dbms_connectors.postgresql_connector import PostgresqlConnector\n",
    "\n",
    "from mlinspect.to_sql.dbms_connectors.umbra_connector import UmbraConnector\n",
    "\n",
    "\n",
    "# DBMS related:\n",
    "UMBRA_USER = \"postgres\"\n",
    "UMBRA_PW = \"\"\n",
    "UMBRA_DB = \"\"\n",
    "UMBRA_PORT = 5433\n",
    "UMBRA_HOST = \"/tmp/\"\n",
    "\n",
    "POSTGRES_USER = \"luca\"\n",
    "POSTGRES_PW = \"password\"\n",
    "POSTGRES_DB = \"healthcare_benchmark\"\n",
    "POSTGRES_PORT = 5432\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "\n",
    "HEALTHCARE_FILE_PY = os.path.join(str(get_project_root()), \"example_pipelines\", \"healthcare\", \"healthcare.py\")\n",
    "COMPAS_FILE_PY = os.path.join(str(get_project_root()), \"example_pipelines\", \"compas\", \"compas.py\")\n",
    "ADULT_SIMPLE_FILE_PY = os.path.join(str(get_project_root()), \"example_pipelines\", \"adult_simple\", \"adult_simple.py\")\n",
    "ADULT_COMPLEX_FILE_PY = os.path.join(str(get_project_root()), \"example_pipelines\", \"adult_complex\", \"adult_complex.py\")\n",
    "\n",
    "# No model training:\n",
    "HEALTHCARE_FILE_PY_R = os.path.join(str(get_project_root()), \"test\", \"monkeypatchingSQL\", \"pipelines_for_tests\",\n",
    "                                    \"healthcare\", \"healthcare_res.py\")\n",
    "COMPAS_FILE_PY_R = os.path.join(str(get_project_root()), \"test\", \"monkeypatchingSQL\", \"pipelines_for_tests\", \"compas\",\n",
    "                              \"compas_res.py\")\n",
    "ADULT_SIMPLE_FILE_PY_R = os.path.join(str(get_project_root()), \"test\", \"monkeypatchingSQL\", \"pipelines_for_tests\",\n",
    "                                    \"adult_simple\", \"adult_simple_res.py\")\n",
    "ADULT_COMPLEX_FILE_PY_R = os.path.join(str(get_project_root()), \"test\", \"monkeypatchingSQL\", \"pipelines_for_tests\",\n",
    "                                     \"adult_complex\", \"adult_complex_res.py\")\n",
    "\n",
    "HEALTHCARE_BIAS = ['age_group', 'race']\n",
    "COMPAS_BIAS = ['sex', 'race']\n",
    "ADULT_SIMPLE_BIAS = ['race']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_inspection(file_location, bias, to_sql, dbms_connector=None, mode=None, materialize=None):\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mlinspect.visualisation import save_fig_to_path\n",
    "\n",
    "    inspector_result = PipelineInspector \\\n",
    "        .on_pipeline_from_py_file(file_location) \\\n",
    "        .add_custom_monkey_patching_module(custom_monkeypatching) #\\\n",
    "        #.add_check(NoBiasIntroducedFor(bias)) \\\n",
    "        #.add_check(NoIllegalFeatures()) \\\n",
    "        #.add_check(NoMissingEmbeddings()) \\\n",
    "        #.add_required_inspection(RowLineage(5)) \\\n",
    "        #.add_required_inspection(MaterializeFirstOutputRows(5))\n",
    "\n",
    "    if to_sql:\n",
    "        inspector_result = inspector_result.execute_in_sql(dbms_connector=dbms_connector, mode=mode,\n",
    "                                                           materialize=materialize)\n",
    "    else:\n",
    "        inspector_result = inspector_result.execute()\n",
    "\n",
    "    extracted_dag = inspector_result.dag\n",
    "    filename = os.path.join(str(get_project_root()), \"demo\", \"feature_overview\", \"healthcare.png\")\n",
    "    save_fig_to_path(extracted_dag, filename)\n",
    "    im = Image.open(filename)\n",
    "    plt.imshow(im)\n",
    "\n",
    "    check_results = inspector_result.check_to_check_results\n",
    "    #no_bias_check_result = check_results[NoBiasIntroducedFor(bias)]\n",
    "\n",
    "    #distribution_changes_overview_df = NoBiasIntroducedFor.get_distribution_changes_overview_as_df(\n",
    "    #    no_bias_check_result)\n",
    "    #result = \"\"\n",
    "    #result += distribution_changes_overview_df.to_markdown()\n",
    "\n",
    "    #for i in list(no_bias_check_result.bias_distribution_change.items()):\n",
    "    #    _, join_distribution_changes = i\n",
    "    #    for column, distribution_change in join_distribution_changes.items():\n",
    "    #        result += \"\\n\"\n",
    "    #        result += f\"\\033[1m Column '{column}'\\033[0m\"\n",
    "    #        result += distribution_change.before_and_after_df.to_markdown()\n",
    "        \n",
    "    #print(result)\n",
    "    result=None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark of default inspection using CTEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dbms_connector_u = UmbraConnector(dbname=UMBRA_DB, user=UMBRA_USER, password=UMBRA_PW, port=UMBRA_PORT, host=UMBRA_HOST)\n",
    "\n",
    "dbms_connector_p = PostgresqlConnector(dbname=POSTGRES_DB, user=POSTGRES_USER, password=POSTGRES_PW,\n",
    "                                       port=POSTGRES_PORT, host=POSTGRES_HOST)\n",
    "\n",
    "def run_for_all(file_location, bias, mode=\"\", materialize=None):\n",
    "    t0 = time.time()\n",
    "    run_inspection(file_location=file_location, bias=bias, to_sql=False)\n",
    "    t1 = time.time()\n",
    "    print(\"\\nTime spend with original (pandas): \" + str(t1 - t0))\n",
    "\n",
    "    t0 = time.time()\n",
    "    run_inspection(file_location=file_location, bias=bias, to_sql=True, dbms_connector=dbms_connector_p, mode=mode,\n",
    "                   materialize=materialize)\n",
    "    t1 = time.time()\n",
    "    print(\"\\nTime spend with modified SQL inspections (PSQL): \" + str(t1 - t0))\n",
    "\n",
    "#    if not materialize: # Materialized not supported by Umbra -> main-memory performance\n",
    "#        t0 = time.time()\n",
    "#       run_inspection(file_location=file_location, bias=bias, to_sql=True, dbms_connector=dbms_connector_u, mode=mode,\n",
    "#                       materialize=materialize)\n",
    "#        t1 = time.time()\n",
    "#       print(\"\\nTime spend with modified SQL inspections (Umbra): \" + str(t1 - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End example of the preprocessing-pipeline inspection + model training:\n",
    "\n",
    "Slightly different inspections results are expected because of the random split. Still, the resulting model accuracy should\n",
    "be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXX HIER IST DER MODIFIED CODE XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"Predicting which patients are at a higher risk of complications\"\"\"\n",
      "import warnings\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from example_pipelines.healthcare.healthcare_utils import MyW2VTransformer, MyKerasClassifier, create_model\n",
      "from mlinspect.utils import get_project_root, store_timestamp\n",
      "import time\n",
      "from mlinspect.to_sql.dbms_connectors.postgresql_connector import PostgresqlConnector\n",
      "warnings.filterwarnings('ignore', **set_code_reference_call(21, 0, 21, 33))\n",
      "COUNTIES_OF_INTEREST = ['county2', 'county3']\n",
      "patients = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(25, 40, 25, 58)), **set_code_reference_call(25,\n",
      "    36, 25, 59)), 'example_pipelines', 'healthcare', 'patients.csv', **\n",
      "    set_code_reference_call(25, 23, 26, 51)), **set_code_reference_call(25,\n",
      "    11, 26, 66, na_values=''))\n",
      "histories = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(27, 41, 27, 59)), **set_code_reference_call(27,\n",
      "    37, 27, 60)), 'example_pipelines', 'healthcare', 'histories.csv', **\n",
      "    set_code_reference_call(27, 24, 28, 53)), **set_code_reference_call(27,\n",
      "    12, 28, 68, na_values=''))\n",
      "data = patients.merge(histories, **set_code_reference_call(32, 7, 32, 44,\n",
      "    on=['ssn']))\n",
      "complications = data.groupby('age_group', **set_code_reference_call(36, 16,\n",
      "    36, 41)).agg(**set_code_reference_call(36, 16, 37, 54,\n",
      "    mean_complications=('complications', 'mean')))\n",
      "data = data.merge(complications, **set_code_reference_call(41, 7, 41, 50,\n",
      "    on=['age_group']))\n",
      "data[set_code_reference_subscript(45, 0, 45, 72, ('label'))] = data[\n",
      "    set_code_reference_subscript(45, 16, 45, 37, ('complications'))\n",
      "    ] > 1.2 * data[set_code_reference_subscript(45, 46, 45, 72, (\n",
      "    'mean_complications'))]\n",
      "data = data[set_code_reference_subscript(49, 7, 49, 89, (['smoker',\n",
      "    'last_name', 'county', 'num_children', 'race', 'income', 'label']))][\n",
      "    set_code_reference_subscript(49, 7, 49, 132, (data[\n",
      "    set_code_reference_subscript(49, 90, 49, 104, ('county'))].isin(\n",
      "    COUNTIES_OF_INTEREST, **set_code_reference_call(49, 90, 49, 131))))]\n",
      "impute_and_one_hot_encode = Pipeline([('impute', SimpleImputer(**\n",
      "    set_code_reference_call(53, 15, 53, 54, strategy='most_frequent'))), (\n",
      "    'encode', OneHotEncoder(**set_code_reference_call(54, 15, 54, 67,\n",
      "    sparse=False, handle_unknown='ignore')))], **set_code_reference_call(52,\n",
      "    28, 55, 2))\n",
      "featurisation = ColumnTransformer(**set_code_reference_call(56, 16, 60, 20,\n",
      "    transformers=[('impute_and_one_hot_encode', impute_and_one_hot_encode,\n",
      "    ['smoker', 'county', 'race']), ('numeric', StandardScaler(**\n",
      "    set_code_reference_call(59, 16, 59, 32)), ['num_children', 'income'])],\n",
      "    remainder='drop'))\n",
      "neural_net = MyKerasClassifier(**set_code_reference_call(61, 13, 61, 89,\n",
      "    build_fn=create_model, epochs=10, batch_size=1, verbose=0))\n",
      "pipeline = Pipeline([('features', featurisation), ('learner', neural_net)],\n",
      "    **set_code_reference_call(62, 11, 64, 29))\n",
      "t0 = time.time(**set_code_reference_call(66, 5, 66, 16))\n",
      "train_data, test_data = train_test_split(data, **set_code_reference_call(67,\n",
      "    24, 67, 46))\n",
      "store_timestamp('train_test_split .. ', time.time(**set_code_reference_call\n",
      "    (68, 40, 68, 51)) - t0, **set_code_reference_call(68, 0, 68, 55))\n",
      "t0 = time.time(**set_code_reference_call(70, 5, 70, 16))\n",
      "model = pipeline.fit(train_data, train_data[set_code_reference_subscript(71,\n",
      "    33, 71, 52, ('label'))], **set_code_reference_call(71, 8, 71, 53))\n",
      "store_timestamp('train_test_split .. ', time.time(**set_code_reference_call\n",
      "    (72, 40, 72, 51)) - t0, **set_code_reference_call(72, 0, 72, 55))\n",
      "t0 = time.time(**set_code_reference_call(74, 5, 74, 16))\n",
      "print('Mean accuracy: {}'.format(model.score(test_data, test_data[\n",
      "    set_code_reference_subscript(75, 56, 75, 74, ('label'))], **\n",
      "    set_code_reference_call(75, 33, 75, 75)), **set_code_reference_call(75,\n",
      "    6, 75, 76)), **set_code_reference_call(75, 0, 75, 77))\n",
      "store_timestamp('train_test_split .. ', time.time(**set_code_reference_call\n",
      "    (76, 40, 76, 51)) - t0, **set_code_reference_call(76, 0, 76, 55))\n",
      "undo_monkey_patch()\n",
      "\n",
      "TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT2\n",
      "üüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüü ergebnis_source_code für dataframevariable in monkeypatching,  patients = pd.read_csv(os.path.join(str(get_project_root()), \"example_pipelines\", \"healthcare\",\n",
      "                                    \"patients.csv\"), na_values='')\n",
      "üüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüüü caller_source_code in monkeypatching,  pd.read_csv(os.path.join(str(get_project_root()), \"example_pipelines\", \"healthcare\",\n",
      "                                    \"patients.csv\"), na_values='')\n",
      "üüüüüüüüüüüüüüüüüüüüüüüüüüüüüü der split[0] patients \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "execute_inspections() takes 5 positional arguments but 8 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12652\\3371987895.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_for_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHEALTHCARE_FILE_PY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHEALTHCARE_BIAS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"VIEW\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaterialize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12652\\2322665230.py\u001b[0m in \u001b[0;36mrun_for_all\u001b[1;34m(file_location, bias, mode, materialize)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_for_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaterialize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrun_inspection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_sql\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTime spend with original (pandas): \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12652\\2554732598.py\u001b[0m in \u001b[0;36mrun_inspection\u001b[1;34m(file_location, bias, to_sql, dbms_connector, mode, materialize)\u001b[0m\n\u001b[0;32m     17\u001b[0m                                                            materialize=materialize)\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0minspector_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspector_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mextracted_dag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspector_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\mlinspect\\_pipeline_inspector.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mInstrument\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexecute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m         return singleton.run(notebook_path=self.notebook_path,\n\u001b[0m\u001b[0;32m     86\u001b[0m                              \u001b[0mpython_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                              \u001b[0mpython_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\mlinspect\\instrumentation\\_pipeline_executor.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, notebook_path, python_path, python_code, inspections, checks, reset_state, track_code_references, custom_monkey_patching, to_sql, dbms_connector, mode, materialize, row_wise)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Here the modified code is created and run:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_inspections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebook_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpython_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpython_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         check_to_results = dict(\n\u001b[0;32m    176\u001b[0m             (check, check.evaluate(self.inspection_results)) for check in checks)\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\mlinspect\\instrumentation\\_pipeline_executor.py\u001b[0m in \u001b[0;36mrun_inspections\u001b[1;34m(self, notebook_path, python_code, python_path)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodified_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;31m# Do the monkey patching and the inspection:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodified_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_code_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipelineExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;31m#compile(modified_code, filename=self.source_code_path, mode=\"exec\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\example_pipelines\\healthcare\\healthcare.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlinspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbms_connectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostgresql_connector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPostgresqlConnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m# FutureWarning: Sklearn 0.24 made a change that breaks remainder='drop', that change will be fixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#  in an upcoming version: https://github.com/scikit-learn/scikit-learn/pull/19263\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\mlinspect\\monkeypatching\\_patch_pandas.py\u001b[0m in \u001b[0;36mpatched_read_csv\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mexecute_patched_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecute_inspections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dime\\sqlundmlinspect\\mlinspect\\mlinspect\\monkeypatching\\_monkey_patching_utils.py\u001b[0m in \u001b[0;36mexecute_patched_func\u001b[1;34m(original_func, execute_inspections_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m                                               \u001b[0msingleton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_lineno_next_call_or_subscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                                               singleton.end_col_offset_next_call_or_subscript)\n\u001b[1;32m---> 95\u001b[1;33m         result=execute_inspections_func(op_id, caller_filename, caller_lineno, caller_code_reference,\n\u001b[0m\u001b[0;32m     96\u001b[0m                                           caller_source_code, targetdf, sourcedf, helper_source_code)\n\u001b[0;32m     97\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: execute_inspections() takes 5 positional arguments but 8 were given"
     ]
    }
   ],
   "source": [
    "run_for_all(HEALTHCARE_FILE_PY, HEALTHCARE_BIAS, mode=\"VIEW\", materialize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_for_all(HEALTHCARE_FILE_PY, HEALTHCARE_BIAS, mode=\"VIEW\", materialize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute and inspect just the inspections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"Predicting which patients are at a higher risk of complications\"\"\"\n",
      "import warnings\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from example_pipelines.healthcare.healthcare_utils import MyW2VTransformer, MyKerasClassifier, create_model\n",
      "from mlinspect.utils import get_project_root\n",
      "warnings.filterwarnings('ignore', **set_code_reference_call(16, 0, 16, 33))\n",
      "COUNTIES_OF_INTEREST = ['county2', 'county3']\n",
      "patients = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(20, 40, 20, 58)), **set_code_reference_call(20,\n",
      "    36, 20, 59)), 'test', 'monkeypatchingSQL', 'pipelines_for_tests',\n",
      "    'healthcare', 'patients.csv', **set_code_reference_call(20, 23, 21, 51)\n",
      "    ), **set_code_reference_call(20, 11, 21, 66, na_values=''))\n",
      "histories = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(22, 41, 22, 59)), **set_code_reference_call(22,\n",
      "    37, 22, 60)), 'test', 'monkeypatchingSQL', 'pipelines_for_tests',\n",
      "    'healthcare', 'histories.csv', **set_code_reference_call(22, 24, 23, 53\n",
      "    )), **set_code_reference_call(22, 12, 23, 68, na_values=''))\n",
      "data = patients.merge(histories, **set_code_reference_call(25, 7, 25, 44,\n",
      "    on=['ssn']))\n",
      "complications = data.groupby('age_group', **set_code_reference_call(26, 16,\n",
      "    26, 41)).agg(**set_code_reference_call(26, 16, 27, 54,\n",
      "    mean_complications=('complications', 'mean')))\n",
      "data = data.merge(complications, **set_code_reference_call(28, 7, 28, 50,\n",
      "    on=['age_group']))\n",
      "data[set_code_reference_subscript(29, 0, 29, 72, ('label'))] = data[\n",
      "    set_code_reference_subscript(29, 16, 29, 37, ('complications'))\n",
      "    ] > 1.2 * data[set_code_reference_subscript(29, 46, 29, 72, (\n",
      "    'mean_complications'))]\n",
      "data = data[set_code_reference_subscript(30, 7, 30, 89, (['smoker',\n",
      "    'last_name', 'county', 'num_children', 'race', 'income', 'label']))]\n",
      "data = data[set_code_reference_subscript(31, 7, 31, 54, (data[\n",
      "    set_code_reference_subscript(31, 12, 31, 26, ('county'))].isin(\n",
      "    COUNTIES_OF_INTEREST, **set_code_reference_call(31, 12, 31, 53))))]\n",
      "impute_and_one_hot_encode = Pipeline([('impute', SimpleImputer(**\n",
      "    set_code_reference_call(34, 15, 34, 54, strategy='most_frequent'))), (\n",
      "    'encode', OneHotEncoder(**set_code_reference_call(35, 15, 35, 67,\n",
      "    sparse=False, handle_unknown='ignore')))], **set_code_reference_call(33,\n",
      "    28, 36, 2))\n",
      "featurisation = ColumnTransformer(**set_code_reference_call(37, 16, 41, 20,\n",
      "    transformers=[('impute_and_one_hot_encode', impute_and_one_hot_encode,\n",
      "    ['smoker', 'county', 'race']), ('numeric', StandardScaler(**\n",
      "    set_code_reference_call(40, 16, 40, 32)), ['num_children', 'income'])],\n",
      "    remainder='drop'))\n",
      "result = featurisation.fit_transform(data, **set_code_reference_call(50, 9,\n",
      "    50, 42))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with original (pandas): 0.046825408935546875\n",
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"Predicting which patients are at a higher risk of complications\"\"\"\n",
      "import warnings\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from example_pipelines.healthcare.healthcare_utils import MyW2VTransformer, MyKerasClassifier, create_model\n",
      "from mlinspect.utils import get_project_root\n",
      "warnings.filterwarnings('ignore', **set_code_reference_call(16, 0, 16, 33))\n",
      "COUNTIES_OF_INTEREST = ['county2', 'county3']\n",
      "patients = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(20, 40, 20, 58)), **set_code_reference_call(20,\n",
      "    36, 20, 59)), 'test', 'monkeypatchingSQL', 'pipelines_for_tests',\n",
      "    'healthcare', 'patients.csv', **set_code_reference_call(20, 23, 21, 51)\n",
      "    ), **set_code_reference_call(20, 11, 21, 66, na_values=''))\n",
      "histories = pd.read_csv(os.path.join(str(get_project_root(**\n",
      "    set_code_reference_call(22, 41, 22, 59)), **set_code_reference_call(22,\n",
      "    37, 22, 60)), 'test', 'monkeypatchingSQL', 'pipelines_for_tests',\n",
      "    'healthcare', 'histories.csv', **set_code_reference_call(22, 24, 23, 53\n",
      "    )), **set_code_reference_call(22, 12, 23, 68, na_values=''))\n",
      "data = patients.merge(histories, **set_code_reference_call(25, 7, 25, 44,\n",
      "    on=['ssn']))\n",
      "complications = data.groupby('age_group', **set_code_reference_call(26, 16,\n",
      "    26, 41)).agg(**set_code_reference_call(26, 16, 27, 54,\n",
      "    mean_complications=('complications', 'mean')))\n",
      "data = data.merge(complications, **set_code_reference_call(28, 7, 28, 50,\n",
      "    on=['age_group']))\n",
      "data[set_code_reference_subscript(29, 0, 29, 72, ('label'))] = data[\n",
      "    set_code_reference_subscript(29, 16, 29, 37, ('complications'))\n",
      "    ] > 1.2 * data[set_code_reference_subscript(29, 46, 29, 72, (\n",
      "    'mean_complications'))]\n",
      "data = data[set_code_reference_subscript(30, 7, 30, 89, (['smoker',\n",
      "    'last_name', 'county', 'num_children', 'race', 'income', 'label']))]\n",
      "data = data[set_code_reference_subscript(31, 7, 31, 54, (data[\n",
      "    set_code_reference_subscript(31, 12, 31, 26, ('county'))].isin(\n",
      "    COUNTIES_OF_INTEREST, **set_code_reference_call(31, 12, 31, 53))))]\n",
      "impute_and_one_hot_encode = Pipeline([('impute', SimpleImputer(**\n",
      "    set_code_reference_call(34, 15, 34, 54, strategy='most_frequent'))), (\n",
      "    'encode', OneHotEncoder(**set_code_reference_call(35, 15, 35, 67,\n",
      "    sparse=False, handle_unknown='ignore')))], **set_code_reference_call(33,\n",
      "    28, 36, 2))\n",
      "featurisation = ColumnTransformer(**set_code_reference_call(37, 16, 41, 20,\n",
      "    transformers=[('impute_and_one_hot_encode', impute_and_one_hot_encode,\n",
      "    ['smoker', 'county', 'race']), ('numeric', StandardScaler(**\n",
      "    set_code_reference_call(40, 16, 40, 32)), ['num_children', 'income'])],\n",
      "    remainder='drop'))\n",
      "result = featurisation.fit_transform(data, **set_code_reference_call(50, 9,\n",
      "    50, 42))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with modified SQL inspections (PSQL): 0.08688831329345703\n"
     ]
    }
   ],
   "source": [
    "run_for_all(HEALTHCARE_FILE_PY_R, HEALTHCARE_BIAS, mode=\"CTE\", materialize=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"\n",
      "An example pipeline\n",
      "\"\"\"\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer, label_binarize\n",
      "from mlinspect.utils import get_project_root\n",
      "train_file = os.path.join(str(get_project_root(**set_code_reference_call(15,\n",
      "    30, 15, 48)), **set_code_reference_call(15, 26, 15, 49)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'compas',\n",
      "    'compas_train.csv', **set_code_reference_call(15, 13, 15, 132))\n",
      "train_data = pd.read_csv(train_file, **set_code_reference_call(16, 13, 16, \n",
      "    63, na_values='', index_col=0))\n",
      "test_file = os.path.join(str(get_project_root(**set_code_reference_call(17,\n",
      "    29, 17, 47)), **set_code_reference_call(17, 25, 17, 48)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'compas', 'compas_test.csv',\n",
      "    **set_code_reference_call(17, 12, 17, 130))\n",
      "test_data = pd.read_csv(test_file, **set_code_reference_call(18, 12, 18, 61,\n",
      "    na_values='', index_col=0))\n",
      "train_data = train_data[set_code_reference_subscript(20, 13, 22, 78, ([\n",
      "    'sex', 'dob', 'age', 'c_charge_degree', 'race', 'score_text',\n",
      "    'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid',\n",
      "    'two_year_recid', 'c_jail_in', 'c_jail_out']))]\n",
      "test_data = test_data[set_code_reference_subscript(23, 12, 25, 78, (['sex',\n",
      "    'dob', 'age', 'c_charge_degree', 'race', 'score_text', 'priors_count',\n",
      "    'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid',\n",
      "    'c_jail_in', 'c_jail_out']))]\n",
      "train_data = train_data[set_code_reference_subscript(27, 13, 27, 119, ((\n",
      "    train_data[set_code_reference_subscript(27, 25, 27, 62, (\n",
      "    'days_b_screening_arrest'))] <= 30) & (train_data[\n",
      "    set_code_reference_subscript(27, 73, 27, 110, (\n",
      "    'days_b_screening_arrest'))] >= -30)))]\n",
      "train_data = train_data[set_code_reference_subscript(28, 13, 28, 53, (\n",
      "    train_data[set_code_reference_subscript(28, 24, 28, 46, ('is_recid'))] !=\n",
      "    -1))]\n",
      "train_data = train_data[set_code_reference_subscript(29, 13, 29, 61, (\n",
      "    train_data[set_code_reference_subscript(29, 24, 29, 53, (\n",
      "    'c_charge_degree'))] != 'O'))]\n",
      "train_data = train_data[set_code_reference_subscript(30, 13, 30, 58, (\n",
      "    train_data[set_code_reference_subscript(30, 24, 30, 48, ('score_text'))\n",
      "    ] != 'N/A'))]\n",
      "train_data = train_data.replace('Medium', 'Low', **set_code_reference_call(\n",
      "    32, 13, 32, 48))\n",
      "test_data = test_data.replace('Medium', 'Low', **set_code_reference_call(33,\n",
      "    12, 33, 46))\n",
      "train_labels = label_binarize(train_data[set_code_reference_subscript(35, \n",
      "    30, 35, 54, ('score_text'))], **set_code_reference_call(35, 15, 35, 80,\n",
      "    classes=['High', 'Low']))\n",
      "test_labels = label_binarize(test_data[set_code_reference_subscript(36, 29,\n",
      "    36, 52, ('score_text'))], **set_code_reference_call(36, 14, 36, 78,\n",
      "    classes=['High', 'Low']))\n",
      "impute1_and_onehot = Pipeline([('imputer1', SimpleImputer(**\n",
      "    set_code_reference_call(38, 44, 38, 83, strategy='most_frequent'))), (\n",
      "    'onehot', OneHotEncoder(**set_code_reference_call(39, 42, 39, 80,\n",
      "    handle_unknown='ignore')))], **set_code_reference_call(38, 21, 39, 83))\n",
      "impute2_and_bin = Pipeline([('imputer2', SimpleImputer(**\n",
      "    set_code_reference_call(40, 41, 40, 71, strategy='mean'))), (\n",
      "    'discretizer', KBinsDiscretizer(**set_code_reference_call(41, 44, 41, \n",
      "    108, n_bins=4, encode='ordinal', strategy='uniform')))], **\n",
      "    set_code_reference_call(40, 18, 41, 111))\n",
      "featurizer = ColumnTransformer(**set_code_reference_call(43, 13, 46, 2,\n",
      "    transformers=[('impute1_and_onehot', impute1_and_onehot, ['is_recid']),\n",
      "    ('impute2_and_bin', impute2_and_bin, ['age'])]))\n",
      "result = featurizer.fit_transform(train_data, **set_code_reference_call(55,\n",
      "    9, 55, 45))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with original (pandas): 0.08891105651855469\n",
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"\n",
      "An example pipeline\n",
      "\"\"\"\n",
      "import os\n",
      "import pandas as pd\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer, label_binarize\n",
      "from mlinspect.utils import get_project_root\n",
      "train_file = os.path.join(str(get_project_root(**set_code_reference_call(15,\n",
      "    30, 15, 48)), **set_code_reference_call(15, 26, 15, 49)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'compas',\n",
      "    'compas_train.csv', **set_code_reference_call(15, 13, 15, 132))\n",
      "train_data = pd.read_csv(train_file, **set_code_reference_call(16, 13, 16, \n",
      "    63, na_values='', index_col=0))\n",
      "test_file = os.path.join(str(get_project_root(**set_code_reference_call(17,\n",
      "    29, 17, 47)), **set_code_reference_call(17, 25, 17, 48)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'compas', 'compas_test.csv',\n",
      "    **set_code_reference_call(17, 12, 17, 130))\n",
      "test_data = pd.read_csv(test_file, **set_code_reference_call(18, 12, 18, 61,\n",
      "    na_values='', index_col=0))\n",
      "train_data = train_data[set_code_reference_subscript(20, 13, 22, 78, ([\n",
      "    'sex', 'dob', 'age', 'c_charge_degree', 'race', 'score_text',\n",
      "    'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid',\n",
      "    'two_year_recid', 'c_jail_in', 'c_jail_out']))]\n",
      "test_data = test_data[set_code_reference_subscript(23, 12, 25, 78, (['sex',\n",
      "    'dob', 'age', 'c_charge_degree', 'race', 'score_text', 'priors_count',\n",
      "    'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid',\n",
      "    'c_jail_in', 'c_jail_out']))]\n",
      "train_data = train_data[set_code_reference_subscript(27, 13, 27, 119, ((\n",
      "    train_data[set_code_reference_subscript(27, 25, 27, 62, (\n",
      "    'days_b_screening_arrest'))] <= 30) & (train_data[\n",
      "    set_code_reference_subscript(27, 73, 27, 110, (\n",
      "    'days_b_screening_arrest'))] >= -30)))]\n",
      "train_data = train_data[set_code_reference_subscript(28, 13, 28, 53, (\n",
      "    train_data[set_code_reference_subscript(28, 24, 28, 46, ('is_recid'))] !=\n",
      "    -1))]\n",
      "train_data = train_data[set_code_reference_subscript(29, 13, 29, 61, (\n",
      "    train_data[set_code_reference_subscript(29, 24, 29, 53, (\n",
      "    'c_charge_degree'))] != 'O'))]\n",
      "train_data = train_data[set_code_reference_subscript(30, 13, 30, 58, (\n",
      "    train_data[set_code_reference_subscript(30, 24, 30, 48, ('score_text'))\n",
      "    ] != 'N/A'))]\n",
      "train_data = train_data.replace('Medium', 'Low', **set_code_reference_call(\n",
      "    32, 13, 32, 48))\n",
      "test_data = test_data.replace('Medium', 'Low', **set_code_reference_call(33,\n",
      "    12, 33, 46))\n",
      "train_labels = label_binarize(train_data[set_code_reference_subscript(35, \n",
      "    30, 35, 54, ('score_text'))], **set_code_reference_call(35, 15, 35, 80,\n",
      "    classes=['High', 'Low']))\n",
      "test_labels = label_binarize(test_data[set_code_reference_subscript(36, 29,\n",
      "    36, 52, ('score_text'))], **set_code_reference_call(36, 14, 36, 78,\n",
      "    classes=['High', 'Low']))\n",
      "impute1_and_onehot = Pipeline([('imputer1', SimpleImputer(**\n",
      "    set_code_reference_call(38, 44, 38, 83, strategy='most_frequent'))), (\n",
      "    'onehot', OneHotEncoder(**set_code_reference_call(39, 42, 39, 80,\n",
      "    handle_unknown='ignore')))], **set_code_reference_call(38, 21, 39, 83))\n",
      "impute2_and_bin = Pipeline([('imputer2', SimpleImputer(**\n",
      "    set_code_reference_call(40, 41, 40, 71, strategy='mean'))), (\n",
      "    'discretizer', KBinsDiscretizer(**set_code_reference_call(41, 44, 41, \n",
      "    108, n_bins=4, encode='ordinal', strategy='uniform')))], **\n",
      "    set_code_reference_call(40, 18, 41, 111))\n",
      "featurizer = ColumnTransformer(**set_code_reference_call(43, 13, 46, 2,\n",
      "    transformers=[('impute1_and_onehot', impute1_and_onehot, ['is_recid']),\n",
      "    ('impute2_and_bin', impute2_and_bin, ['age'])]))\n",
      "result = featurizer.fit_transform(train_data, **set_code_reference_call(55,\n",
      "    9, 55, 45))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with modified SQL inspections (PSQL): 0.1648845672607422\n"
     ]
    }
   ],
   "source": [
    "run_for_all(COMPAS_FILE_PY_R, COMPAS_BIAS, mode=\"CTE\", materialize=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline start\n",
      "\n",
      "Time spend with original (pandas): 0.06773543357849121\n",
      "pipeline start\n",
      "\n",
      "Time spend with modified SQL inspections (PSQL): 0.10215044021606445\n"
     ]
    }
   ],
   "source": [
    "run_for_all(ADULT_SIMPLE_FILE_PY_R, ADULT_SIMPLE_BIAS, mode=\"CTE\", materialize=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"\n",
      "An example pipeline\n",
      "\"\"\"\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from mlinspect.utils import get_project_root\n",
      "train_file = os.path.join(str(get_project_root(**set_code_reference_call(17,\n",
      "    30, 17, 48)), **set_code_reference_call(17, 26, 17, 49)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'adult_complex',\n",
      "    'adult_train.csv', **set_code_reference_call(17, 13, 17, 138))\n",
      "train_data = pd.read_csv(train_file, **set_code_reference_call(18, 13, 18, \n",
      "    63, na_values='', index_col=0))\n",
      "test_file = os.path.join(str(get_project_root(**set_code_reference_call(19,\n",
      "    29, 19, 47)), **set_code_reference_call(19, 25, 19, 48)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'adult_complex',\n",
      "    'adult_test.csv', **set_code_reference_call(19, 12, 19, 136))\n",
      "test_data = pd.read_csv(test_file, **set_code_reference_call(20, 12, 20, 61,\n",
      "    na_values='', index_col=0))\n",
      "train_labels = preprocessing.label_binarize(train_data[\n",
      "    set_code_reference_subscript(22, 44, 22, 73, ('income-per-year'))], **\n",
      "    set_code_reference_call(22, 15, 22, 101, classes=['>50K', '<=50K']))\n",
      "test_labels = preprocessing.label_binarize(test_data[\n",
      "    set_code_reference_subscript(23, 43, 23, 71, ('income-per-year'))], **\n",
      "    set_code_reference_call(23, 14, 23, 99, classes=['>50K', '<=50K']))\n",
      "nested_categorical_feature_transformation = Pipeline([('impute',\n",
      "    SimpleImputer(**set_code_reference_call(26, 19, 26, 81, missing_values=\n",
      "    np.nan, strategy='most_frequent'))), ('encode', OneHotEncoder(**\n",
      "    set_code_reference_call(27, 19, 27, 57, handle_unknown='ignore')))], **\n",
      "    set_code_reference_call(25, 44, 28, 6))\n",
      "nested_feature_transformation = ColumnTransformer(**set_code_reference_call\n",
      "    (30, 32, 33, 6, transformers=[('categorical',\n",
      "    nested_categorical_feature_transformation, ['education', 'workclass']),\n",
      "    ('numeric', StandardScaler(**set_code_reference_call(32, 20, 32, 36)),\n",
      "    ['age', 'hours-per-week'])]))\n",
      "result = nested_feature_transformation.fit_transform(train_data, **\n",
      "    set_code_reference_call(43, 9, 43, 64))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with original (pandas): 0.09511947631835938\n",
      "from mlinspect.instrumentation._pipeline_executor import set_code_reference_call, set_code_reference_subscript, monkey_patch, undo_monkey_patch\n",
      "monkey_patch()\n",
      "\"\"\"\n",
      "An example pipeline\n",
      "\"\"\"\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from mlinspect.utils import get_project_root\n",
      "train_file = os.path.join(str(get_project_root(**set_code_reference_call(17,\n",
      "    30, 17, 48)), **set_code_reference_call(17, 26, 17, 49)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'adult_complex',\n",
      "    'adult_train.csv', **set_code_reference_call(17, 13, 17, 138))\n",
      "train_data = pd.read_csv(train_file, **set_code_reference_call(18, 13, 18, \n",
      "    63, na_values='', index_col=0))\n",
      "test_file = os.path.join(str(get_project_root(**set_code_reference_call(19,\n",
      "    29, 19, 47)), **set_code_reference_call(19, 25, 19, 48)), 'test',\n",
      "    'monkeypatchingSQL', 'pipelines_for_tests', 'adult_complex',\n",
      "    'adult_test.csv', **set_code_reference_call(19, 12, 19, 136))\n",
      "test_data = pd.read_csv(test_file, **set_code_reference_call(20, 12, 20, 61,\n",
      "    na_values='', index_col=0))\n",
      "train_labels = preprocessing.label_binarize(train_data[\n",
      "    set_code_reference_subscript(22, 44, 22, 73, ('income-per-year'))], **\n",
      "    set_code_reference_call(22, 15, 22, 101, classes=['>50K', '<=50K']))\n",
      "test_labels = preprocessing.label_binarize(test_data[\n",
      "    set_code_reference_subscript(23, 43, 23, 71, ('income-per-year'))], **\n",
      "    set_code_reference_call(23, 14, 23, 99, classes=['>50K', '<=50K']))\n",
      "nested_categorical_feature_transformation = Pipeline([('impute',\n",
      "    SimpleImputer(**set_code_reference_call(26, 19, 26, 81, missing_values=\n",
      "    np.nan, strategy='most_frequent'))), ('encode', OneHotEncoder(**\n",
      "    set_code_reference_call(27, 19, 27, 57, handle_unknown='ignore')))], **\n",
      "    set_code_reference_call(25, 44, 28, 6))\n",
      "nested_feature_transformation = ColumnTransformer(**set_code_reference_call\n",
      "    (30, 32, 33, 6, transformers=[('categorical',\n",
      "    nested_categorical_feature_transformation, ['education', 'workclass']),\n",
      "    ('numeric', StandardScaler(**set_code_reference_call(32, 20, 32, 36)),\n",
      "    ['age', 'hours-per-week'])]))\n",
      "result = nested_feature_transformation.fit_transform(train_data, **\n",
      "    set_code_reference_call(43, 9, 43, 64))\n",
      "undo_monkey_patch()\n",
      "\n",
      "\n",
      "Time spend with modified SQL inspections (PSQL): 0.14703702926635742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dime\\sqlundmlinspect\\mlinspect\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:42: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "c:\\users\\dime\\sqlundmlinspect\\mlinspect\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:42: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "c:\\users\\dime\\sqlundmlinspect\\mlinspect\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:42: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n",
      "c:\\users\\dime\\sqlundmlinspect\\mlinspect\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:42: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    }
   ],
   "source": [
    "run_for_all(ADULT_COMPLEX_FILE_PY_R, ADULT_SIMPLE_BIAS, mode=\"CTE\", materialize=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88cf9573b7b8588226248109e4f46f163d87635f37520c23a7b39ed1f0288615"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
